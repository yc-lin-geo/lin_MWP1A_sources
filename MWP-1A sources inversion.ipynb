{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Basic Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load modules\n",
    "import numpy as np #version 1.18.1\n",
    "import pandas as pd #version 1.0.1\n",
    "from scipy.optimize import nnls #version 1.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load RSL rise magnitude at each site\n",
    "#------------------Empirical Senario------------------\n",
    "Emp_mag = pd.read_excel('RSL magnitude/Lin et al., Sup data.xlsx',sheet_name=1) \n",
    "Tahiti_emp_dis = Emp_mag['Tahiti']\n",
    "Tahiti_emp_std = np.std(Tahiti_emp_dis)\n",
    "Barbados_emp_dis =  Emp_mag['Barbados']\n",
    "Barbados_emp_std = np.std(Barbados_emp_dis)\n",
    "Sunda_emp_dis =  Emp_mag['Sunda Shelf']\n",
    "Sunda_emp_std = np.std(Sunda_emp_dis)\n",
    "HYD_emp_dis =  Emp_mag['Hydrographer\\'s Passage (HYD)']\n",
    "HYD_emp_std = np.std(HYD_emp_dis)\n",
    "NOG_emp_dis =  Emp_mag['Noggin Pass (NOG)']\n",
    "NOG_emp_std = np.std(NOG_emp_dis)\n",
    "Scot_emp_dis =  Emp_mag['Northwest Scotland']\n",
    "Scot_emp_std = np.std(Scot_emp_dis)\n",
    "total_emp_std = np.array([Tahiti_emp_std,Barbados_emp_std,Sunda_emp_std,HYD_emp_std,NOG_emp_std,\n",
    "                        Scot_emp_std]) \n",
    "#------------------Uniform Senario------------------\n",
    "Uni_mag = pd.read_excel('RSL magnitude/Lin et al., Sup data.xlsx',sheet_name=2) #Uniform Senario\n",
    "Tahiti_uni_dis = Uni_mag['Tahiti']\n",
    "Tahiti_uni_std = np.std(Tahiti_uni_dis)\n",
    "Barbados_uni_dis =  Uni_mag['Barbados']\n",
    "Barbados_uni_std = np.std(Barbados_uni_dis)\n",
    "Sunda_uni_dis =  Uni_mag['Sunda Shelf']\n",
    "Sunda_uni_std = np.std(Sunda_uni_dis)\n",
    "HYD_uni_dis =  Uni_mag['Hydrographer\\'s Passage (HYD)']\n",
    "HYD_uni_std = np.std(HYD_uni_dis)\n",
    "NOG_uni_dis =  Uni_mag['Noggin Pass (NOG)']\n",
    "NOG_uni_std = np.std(NOG_uni_dis)\n",
    "Scot_uni_dis =  Uni_mag['Northwest Scotland']\n",
    "Scot_uni_std = np.std(Scot_uni_dis)\n",
    "total_uni_std = np.array([Tahiti_uni_std,Barbados_uni_std,Sunda_uni_std,HYD_uni_std,NOG_uni_std,\n",
    "                        Scot_uni_std])\n",
    "#load sea-level fingerprint matrix\n",
    "#each row corresponds to each sea-level site and each column corresponds to each ice sheet\n",
    "A = np.loadtxt('RSL magnitude/fingerprint.csv',delimiter=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_maximum_prob(values,percent):\n",
    "    '''This function is used to analytically find the smallest confidence interval  \n",
    "    range from a data ensemble \n",
    "    values:  data samples\n",
    "    percent: probablity range to find (e.g., 95 is 95% CI)'''\n",
    "    \n",
    "    v_max,v_min = np.max(values),np.min(values)\n",
    "    ranges = []\n",
    "    for i in np.linspace(0,100-percent,1000):\n",
    "        _b,_e = np.percentile(values,[i,i+percent])\n",
    "        ranges.append([_b,_e,np.abs(_b-_e),i,i+percent])\n",
    "    ranges = np.array(ranges)\n",
    "    min_index = np.argmin(ranges[:,2])\n",
    "    \n",
    "    return ranges[min_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. MWP-1A Sources Inversion\n",
    "\n",
    "### Empirical senario for coral records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------MWP1A Magnitude & Sources with Empirical Distribution -\n",
      "----------------Mean Result (95% confidence interval)----------------\n",
      "NAIS: 12.263 [0.000,18.573]\n",
      "AIS: 2.548 [0.000,10.673]\n",
      "SIS:   3.472 [0.000,6.582]\n",
      "Total MWP-1A Magnitude:   18.284 [14.485,21.957]\n"
     ]
    }
   ],
   "source": [
    "emp_result = []\n",
    "while len(emp_result)<20000:\n",
    "    i = np.random.randint(0,20000,1)[0]\n",
    "    obs = np.array([Tahiti_emp_dis.iloc[i],Barbados_emp_dis.iloc[i],Sunda_emp_dis.iloc[i],HYD_emp_dis.iloc[i],\n",
    "                   NOG_emp_dis.iloc[i],Scot_emp_dis.iloc[i]]) #compile all sample together\n",
    "    opti = list(nnls(np.sqrt(1/np.array(total_emp_std)**2)[:,None] * A,np.sqrt(1/np.array(total_emp_std)**2)*obs)[0]) #non-negative least square\n",
    "    emp_result.append(opti)\n",
    "    \n",
    "emp_result= np.array(emp_result)\n",
    "print('----------------MWP1A Magnitude & Sources with Empirical Distribution -')\n",
    "print('----------------Mean Result (95% confidence interval)----------------')\n",
    "print('NAIS: {0:5.3f} [{1:5.3f},{2:5.3f}]'.format(np.mean(emp_result[:,0]),*find_maximum_prob(emp_result[:,0],95)[:2]))\n",
    "print('AIS: {0:5.3f} [{1:5.3f},{2:5.3f}]'.format(np.mean(emp_result[:,1]),*find_maximum_prob(emp_result[:,1],95)[:2]))\n",
    "print('SIS:   {0:5.3f} [{1:5.3f},{2:5.3f}]'.format(np.mean(emp_result[:,2]),*find_maximum_prob(emp_result[:,2],95)[:2]))\n",
    "print('Total MWP-1A Magnitude:   {0:5.3f} [{1:5.3f},{2:5.3f}]'.format(np.mean(np.sum(emp_result,axis=1)),*find_maximum_prob(np.sum(emp_result,axis=1),95)[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform senario coral records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------MWP1A Magnitude & Sources with Uniform Distribution -\n",
      "----------------Mean Result (95% confidence interval)----------------\n",
      "NAIS: 12.462 [2.952,19.095]\n",
      "AIS: 2.145 [0.000,8.718]\n",
      "SIS:   3.138 [0.000,5.961]\n",
      "Total MWP-1A Magnitude:   17.745 [14.997,20.563]\n"
     ]
    }
   ],
   "source": [
    "uni_result = []\n",
    "while len(uni_result)<20000:\n",
    "    i = np.random.randint(0,20000,1)[0]\n",
    "    obs = np.array([Tahiti_uni_dis.iloc[i],Barbados_uni_dis.iloc[i],Sunda_uni_dis.iloc[i],HYD_uni_dis.iloc[i],\n",
    "                   NOG_uni_dis.iloc[i],Scot_uni_dis.iloc[i]]) #compile all sample together\n",
    "    opti = list(nnls(np.sqrt(1/np.array(total_uni_std)**2)[:,None] * A,np.sqrt(1/np.array(total_uni_std)**2)*obs)[0]) #non-negative least square\n",
    "    uni_result.append(opti)\n",
    "    \n",
    "uni_result= np.array(uni_result)\n",
    "print('----------------MWP1A Magnitude & Sources with Uniform Distribution -')\n",
    "print('----------------Mean Result (95% confidence interval)----------------')\n",
    "print('NAIS: {0:5.3f} [{1:5.3f},{2:5.3f}]'.format(np.mean(uni_result[:,0]),*find_maximum_prob(uni_result[:,0],95)[:2]))\n",
    "print('AIS: {0:5.3f} [{1:5.3f},{2:5.3f}]'.format(np.mean(uni_result[:,1]),*find_maximum_prob(uni_result[:,1],95)[:2]))\n",
    "print('SIS:   {0:5.3f} [{1:5.3f},{2:5.3f}]'.format(np.mean(uni_result[:,2]),*find_maximum_prob(uni_result[:,2],95)[:2]))\n",
    "print('Total MWP-1A Magnitude:   {0:5.3f} [{1:5.3f},{2:5.3f}]'.format(np.mean(np.sum(uni_result,axis=1)),*find_maximum_prob(np.sum(uni_result,axis=1),95)[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Jackknife Resampling\n",
    "\n",
    "### Empirical senario for coral records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Without Tahiti -------------------------------------\n",
      "----------------MWP1A Magnitude & Sources with Empirical Distribution -----------\n",
      "----------------Mean Result [95% confidence interval] (1 std)-----------------\n",
      "North American Ice Sheet: 11.428 [0.000,19.215]  (6.233)\n",
      "West Antarctic Ice Sheet: 3.026 [0.000,11.770] (4.381)\n",
      "Scandinavian Ice Sheet:   3.488 [0.000,6.554]  (2.002)\n",
      "----------------------------------------------------------------------\n",
      "----------------Without Barbados -------------------------------------\n",
      "----------------MWP1A Magnitude & Sources with Empirical Distribution -----------\n",
      "----------------Mean Result [95% confidence interval] (1 std)-----------------\n",
      "North American Ice Sheet: 7.615 [0.000,18.145]  (7.284)\n",
      "West Antarctic Ice Sheet: 6.882 [0.000,16.188] (6.304)\n",
      "Scandinavian Ice Sheet:   5.117 [0.000,9.909]  (2.934)\n",
      "----------------------------------------------------------------------\n",
      "----------------Without Sunda Shelf -------------------------------------\n",
      "----------------MWP1A Magnitude & Sources with Empirical Distribution -----------\n",
      "----------------Mean Result [95% confidence interval] (1 std)-----------------\n",
      "North American Ice Sheet: 12.503 [0.000,18.739]  (5.034)\n",
      "West Antarctic Ice Sheet: 2.409 [0.000,10.594] (3.635)\n",
      "Scandinavian Ice Sheet:   3.488 [0.000,6.610]  (2.024)\n",
      "----------------------------------------------------------------------\n",
      "----------------Without Hydrographer -------------------------------------\n",
      "----------------MWP1A Magnitude & Sources with Empirical Distribution -----------\n",
      "----------------Mean Result [95% confidence interval] (1 std)-----------------\n",
      "North American Ice Sheet: 11.554 [0.000,18.259]  (5.400)\n",
      "West Antarctic Ice Sheet: 2.922 [0.000,11.131] (3.911)\n",
      "Scandinavian Ice Sheet:   3.430 [0.000,6.498]  (1.994)\n",
      "----------------------------------------------------------------------\n",
      "----------------Without Noggin Pass -------------------------------------\n",
      "----------------MWP1A Magnitude & Sources with Empirical Distribution -----------\n",
      "----------------Mean Result [95% confidence interval] (1 std)-----------------\n",
      "North American Ice Sheet: 11.957 [0.000,18.486]  (5.223)\n",
      "West Antarctic Ice Sheet: 2.717 [0.000,10.945] (3.794)\n",
      "Scandinavian Ice Sheet:   3.447 [0.000,6.483]  (2.005)\n",
      "----------------------------------------------------------------------\n",
      "----------------Without Scotland -------------------------------------\n",
      "----------------MWP1A Magnitude & Sources with Empirical Distribution -----------\n",
      "----------------Mean Result [95% confidence interval] (1 std)-----------------\n",
      "North American Ice Sheet: 14.043 [0.000,21.064]  (6.149)\n",
      "West Antarctic Ice Sheet: 2.874 [0.000,13.130] (4.459)\n",
      "Scandinavian Ice Sheet:   1.410 [0.000,10.632]  (3.703)\n",
      "----------------------------------------------------------------------\n",
      "----------------Overall Jackknife/Original Results --------------------\n",
      "NAIS: 11.517, 12.263  Bias: -0.746 Bias Corrected: 13.010 m\n",
      "AIS: 3.472, 2.548  Bias: 0.923 Bias Corrected: 1.625 m\n",
      "SIS:   3.397, 3.472  Bias: -0.076 Bias Corrected: 3.548 m\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "jack_knife_result =np.zeros([60000,3])\n",
    "site_name = ['Tahiti',\"Barbados\",'Sunda Shelf','Hydrographer','Noggin Pass',\n",
    "            'Scotland']\n",
    "for jack in range(6):\n",
    "    \n",
    "    all_emp_result = [Tahiti_emp_dis,Barbados_emp_dis,Sunda_emp_dis,NOG_emp_dis,\n",
    "                           HYD_emp_dis,Scot_emp_dis]\n",
    "    total_emp_std = [Tahiti_emp_std,Barbados_emp_std,Sunda_emp_std,HYD_emp_std,NOG_emp_std,\n",
    "                         Scot_emp_std]\n",
    "    A_index = ~(np.arange(0,6)==jack)\n",
    "    A_jack = A[A_index]\n",
    "\n",
    "    del all_emp_result[jack] #remove one site's observation\n",
    "    del total_emp_std[jack] #remove one site's standard error \n",
    "    emp_test_result = []\n",
    "    all_emp_result = np.array(all_emp_result)\n",
    "    total_emp_std = np.array(total_emp_std)\n",
    "    while len(emp_test_result)<10000:\n",
    "        \n",
    "        i = np.random.randint(0,20000,1)[0]\n",
    "        obs = np.array([Tahiti_emp_dis.iloc[i],Barbados_emp_dis.iloc[i],Sunda_emp_dis.iloc[i],HYD_emp_dis.iloc[i],\n",
    "                       NOG_emp_dis.iloc[i],Scot_emp_dis.iloc[i]])\n",
    "        obs = obs[A_index] \n",
    "        opti = list(nnls(np.sqrt(1/np.array(total_emp_std)**2)[:,None] * A_jack,np.sqrt(1/np.array(total_emp_std)**2)*obs)[0])\n",
    "        emp_test_result.append(opti)\n",
    "       \n",
    "    \n",
    "    emp_test_result= np.array(emp_test_result)\n",
    "    jack_knife_result[jack*10000:(jack+1)*10000,:]=emp_test_result\n",
    "    print('----------------Without {:} -------------------------------------'.format(site_name[jack]))\n",
    "    print('----------------MWP1A Magnitude & Sources with Empirical Distribution -----------')\n",
    "    print('----------------Mean Result [95% confidence interval] (1 std)-----------------')\n",
    "    print('North American Ice Sheet: {0:5.3f} [{1:5.3f},{2:5.3f}]  ({3:5.3f})'.format(np.mean(emp_test_result[:,0]),find_maximum_prob(emp_test_result[:,0],95)[0],find_maximum_prob(emp_test_result[:,0],95)[1],\n",
    "                                                                                   np.std(emp_test_result[:,0])))\n",
    "    print('West Antarctic Ice Sheet: {0:5.3f} [{1:5.3f},{2:5.3f}] ({3:5.3f})'.format(np.mean(emp_test_result[:,1]),find_maximum_prob(emp_test_result[:,1],95)[0],find_maximum_prob(emp_test_result[:,1],95)[1],\n",
    "                                                                                  np.std(emp_test_result[:,1])))\n",
    "    print('Scandinavian Ice Sheet:   {0:5.3f} [{1:5.3f},{2:5.3f}]  ({3:5.3f})'.format(np.mean(emp_test_result[:,2]),find_maximum_prob(emp_test_result[:,2],95)[0],find_maximum_prob(emp_test_result[:,2],95)[1],\n",
    "                                                                                  np.std(emp_test_result[:,2])))\n",
    "    print('----------------------------------------------------------------------')\n",
    "\n",
    "print('----------------Overall Jackknife/Original Results --------------------')\n",
    "print('NAIS: {0:5.3f}, {1:5.3f}  Bias: {2:5.3f} Bias Corrected: {3:5.3f} m'.format(np.mean(jack_knife_result[:,0]),np.mean(emp_result[:,0]),\n",
    "                                                                           np.mean(jack_knife_result[:,0])-np.mean(emp_result[:,0]),\n",
    "                                                                            np.mean(emp_result[:,0])-(np.mean(jack_knife_result[:,0])-np.mean(emp_result[:,0]))))\n",
    "print('AIS: {0:5.3f}, {1:5.3f}  Bias: {2:5.3f} Bias Corrected: {3:5.3f} m'.format(np.mean(jack_knife_result[:,1]),np.mean(emp_result[:,1]),\n",
    "                                                                           np.mean(jack_knife_result[:,1])-np.mean(emp_result[:,1]),\n",
    "                                                                           np.mean(emp_result[:,1])-(np.mean(jack_knife_result[:,1])-np.mean(emp_result[:,1]))))\n",
    "print('SIS:   {0:5.3f}, {1:5.3f}  Bias: {2:5.3f} Bias Corrected: {3:5.3f} m'.format(np.mean(jack_knife_result[:,2]),np.mean(emp_result[:,2]),\n",
    "                                                                          np.mean(jack_knife_result[:,2])-np.mean(emp_result[:,2]),\n",
    "                                                                        np.mean(emp_result[:,2])-( np.mean(jack_knife_result[:,2])-np.mean(emp_result[:,2]))))\n",
    "print('----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform senario coral records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Without Tahiti -------------------------------------\n",
      "----------------MWP1A Magnitude & Sources with Uniform Distribution -----------\n",
      "----------------Mean Result [95% confidence interval] (1 std)-----------------\n",
      "North American Ice Sheet: 10.613 [0.000,18.423]  (4.201)\n",
      "West Antarctic Ice Sheet: 3.316 [0.000,11.492] (4.293)\n",
      "Scandinavian Ice Sheet:   3.202 [0.000,6.022]  (1.891)\n",
      "----------------------------------------------------------------------\n",
      "----------------Without Barbados -------------------------------------\n",
      "----------------MWP1A Magnitude & Sources with Uniform Distribution -----------\n",
      "----------------Mean Result [95% confidence interval] (1 std)-----------------\n",
      "North American Ice Sheet: 8.753 [0.000,17.220]  (4.201)\n",
      "West Antarctic Ice Sheet: 5.476 [0.000,15.129] (5.916)\n",
      "Scandinavian Ice Sheet:   4.409 [0.000,8.735]  (2.613)\n",
      "----------------------------------------------------------------------\n",
      "----------------Without Sunda Shelf -------------------------------------\n",
      "----------------MWP1A Magnitude & Sources with Uniform Distribution -----------\n",
      "----------------Mean Result [95% confidence interval] (1 std)-----------------\n",
      "North American Ice Sheet: 12.554 [3.419,19.298]  (4.201)\n",
      "West Antarctic Ice Sheet: 2.072 [0.000,8.827] (3.012)\n",
      "Scandinavian Ice Sheet:   3.151 [0.000,5.997]  (1.898)\n",
      "----------------------------------------------------------------------\n",
      "----------------Without Hydrographer -------------------------------------\n",
      "----------------MWP1A Magnitude & Sources with Uniform Distribution -----------\n",
      "----------------Mean Result [95% confidence interval] (1 std)-----------------\n",
      "North American Ice Sheet: 12.369 [2.995,19.431]  (4.201)\n",
      "West Antarctic Ice Sheet: 2.209 [0.000,8.836] (3.082)\n",
      "Scandinavian Ice Sheet:   3.097 [0.000,5.958]  (1.890)\n",
      "----------------------------------------------------------------------\n",
      "----------------Without Noggin Pass -------------------------------------\n",
      "----------------MWP1A Magnitude & Sources with Uniform Distribution -----------\n",
      "----------------Mean Result [95% confidence interval] (1 std)-----------------\n",
      "North American Ice Sheet: 12.384 [2.961,19.352]  (4.201)\n",
      "West Antarctic Ice Sheet: 2.185 [0.000,8.925] (3.054)\n",
      "Scandinavian Ice Sheet:   3.121 [0.000,6.004]  (1.897)\n",
      "----------------------------------------------------------------------\n",
      "----------------Without Scotland -------------------------------------\n",
      "----------------MWP1A Magnitude & Sources with Uniform Distribution -----------\n",
      "----------------Mean Result [95% confidence interval] (1 std)-----------------\n",
      "North American Ice Sheet: 13.705 [3.107,21.150]  (4.201)\n",
      "West Antarctic Ice Sheet: 2.228 [0.000,10.008] (3.546)\n",
      "Scandinavian Ice Sheet:   1.853 [0.000,11.557]  (3.884)\n",
      "----------------------------------------------------------------------\n",
      "----------------Overall Jackknife/Original Results --------------------\n",
      "NAIS: 11.729, 12.462  Bias: -0.732 Bias Corrected: 13.194 m\n",
      "AIS: 2.914, 2.145  Bias: 0.769 Bias Corrected: 1.377 m\n",
      "SIS:   3.139, 3.138  Bias: 0.001 Bias Corrected: 3.137 m\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "jack_knife_result =np.zeros([60000,3])\n",
    "site_name = ['Tahiti',\"Barbados\",'Sunda Shelf','Hydrographer','Noggin Pass',\n",
    "            'Scotland']\n",
    "for jack in range(6):\n",
    "    \n",
    "    all_uni_result = [Tahiti_uni_dis,Barbados_uni_dis,Sunda_uni_dis,NOG_uni_dis,\n",
    "                           HYD_uni_dis,Scot_uni_dis]\n",
    "    total_uni_std = [Tahiti_uni_std,Barbados_uni_std,Sunda_uni_std,HYD_uni_std,NOG_uni_std,\n",
    "                         Scot_uni_std]\n",
    "    A_index = ~(np.arange(0,6)==jack)\n",
    "    A_jack = A[A_index]\n",
    "\n",
    "    del all_uni_result[jack] #remove one site's observation\n",
    "    del total_uni_std[jack] #remove one site's standard error \n",
    "    uni_test_result = []\n",
    "    all_uni_result = np.array(all_uni_result)\n",
    "    total_uni_std = np.array(total_uni_std)\n",
    "    while len(uni_test_result)<10000:\n",
    "        \n",
    "        i = np.random.randint(0,20000,1)[0]\n",
    "        obs = np.array([Tahiti_uni_dis.iloc[i],Barbados_uni_dis.iloc[i],Sunda_uni_dis.iloc[i],HYD_uni_dis.iloc[i],\n",
    "                       NOG_uni_dis.iloc[i],Scot_uni_dis.iloc[i]])\n",
    "        obs = obs[A_index] \n",
    "        opti = list(nnls(np.sqrt(1/np.array(total_uni_std)**2)[:,None] * A_jack,np.sqrt(1/np.array(total_uni_std)**2)*obs)[0])\n",
    "        uni_test_result.append(opti)\n",
    "       \n",
    "    \n",
    "    uni_test_result= np.array(uni_test_result)\n",
    "    jack_knife_result[jack*10000:(jack+1)*10000,:]=uni_test_result\n",
    "    print('----------------Without {:} -------------------------------------'.format(site_name[jack]))\n",
    "    print('----------------MWP1A Magnitude & Sources with Uniform Distribution -----------')\n",
    "    print('----------------Mean Result [95% confidence interval] (1 std)-----------------')\n",
    "    print('North American Ice Sheet: {0:5.3f} [{1:5.3f},{2:5.3f}]  ({3:5.3f})'.format(np.mean(uni_test_result[:,0]),find_maximum_prob(uni_test_result[:,0],95)[0],find_maximum_prob(uni_test_result[:,0],95)[1],\n",
    "                                                                                   np.std(uni_result[:,0])))\n",
    "    print('West Antarctic Ice Sheet: {0:5.3f} [{1:5.3f},{2:5.3f}] ({3:5.3f})'.format(np.mean(uni_test_result[:,1]),find_maximum_prob(uni_test_result[:,1],95)[0],find_maximum_prob(uni_test_result[:,1],95)[1],\n",
    "                                                                                  np.std(uni_test_result[:,1])))\n",
    "    print('Scandinavian Ice Sheet:   {0:5.3f} [{1:5.3f},{2:5.3f}]  ({3:5.3f})'.format(np.mean(uni_test_result[:,2]),find_maximum_prob(uni_test_result[:,2],95)[0],find_maximum_prob(uni_test_result[:,2],95)[1],\n",
    "                                                                                  np.std(uni_test_result[:,2])))\n",
    "    print('----------------------------------------------------------------------')\n",
    "\n",
    "print('----------------Overall Jackknife/Original Results --------------------')\n",
    "print('NAIS: {0:5.3f}, {1:5.3f}  Bias: {2:5.3f} Bias Corrected: {3:5.3f} m'.format(np.mean(jack_knife_result[:,0]),np.mean(uni_result[:,0]),\n",
    "                                                                           np.mean(jack_knife_result[:,0])-np.mean(uni_result[:,0]),\n",
    "                                                                            np.mean(uni_result[:,0])-(np.mean(jack_knife_result[:,0])-np.mean(uni_result[:,0]))))\n",
    "print('AIS: {0:5.3f}, {1:5.3f}  Bias: {2:5.3f} Bias Corrected: {3:5.3f} m'.format(np.mean(jack_knife_result[:,1]),np.mean(uni_result[:,1]),\n",
    "                                                                           np.mean(jack_knife_result[:,1])-np.mean(uni_result[:,1]),\n",
    "                                                                           np.mean(uni_result[:,1])-(np.mean(jack_knife_result[:,1])-np.mean(uni_result[:,1]))))\n",
    "print('SIS:   {0:5.3f}, {1:5.3f}  Bias: {2:5.3f} Bias Corrected: {3:5.3f} m'.format(np.mean(jack_knife_result[:,2]),np.mean(uni_result[:,2]),\n",
    "                                                                          np.mean(jack_knife_result[:,2])-np.mean(uni_result[:,2]),\n",
    "                                                                        np.mean(uni_result[:,2])-( np.mean(jack_knife_result[:,2])-np.mean(uni_result[:,2]))))\n",
    "print('----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. MWP-1A Sources Inversion with sea-level oscillation limit\n",
    "\n",
    "### Empirical senario for coral records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------MWP1A Magnitude & Sources with Empirical Distribution -----------\n",
      "----------------Mean Result (95% confidence interval)----------------\n",
      "NAIS: [015.669,15.669]\n",
      "AIS:  [0.000,9.444]\n",
      "SIS:  [2.850,7.595]\n",
      "Total MWP-1A Magnitude:    [14.396,21.748]\n"
     ]
    }
   ],
   "source": [
    "emp_result = []\n",
    "total_emp_std = np.array([Tahiti_emp_std,Barbados_emp_std,Sunda_emp_std,HYD_emp_std,NOG_emp_std,\n",
    "                        Scot_emp_std]) \n",
    "while len(emp_result)<20000:\n",
    "    i = np.random.randint(0,20000,1)[0]\n",
    "    obs = np.array([Tahiti_emp_dis.iloc[i],Barbados_emp_dis.iloc[i],Sunda_emp_dis.iloc[i],HYD_emp_dis.iloc[i],\n",
    "                   NOG_emp_dis.iloc[i],Scot_emp_dis.iloc[i]]) #compile all sample together\n",
    "    opti = list(nnls(np.sqrt(1/np.array(total_emp_std)**2)[:,None] * A,np.sqrt(1/np.array(total_emp_std)**2)*obs)[0]) #non-negative least square\n",
    "    if (opti[0]*0.75+opti[1]*1.09-opti[2]*0.74)<9: # filter out the results producing a sea-level oscillation\n",
    "        emp_result.append(opti)\n",
    "    \n",
    "emp_result= np.array(emp_result)\n",
    "print('----------------MWP1A Magnitude & Sources with Empirical Distribution -----------')\n",
    "print('----------------Mean Result (95% confidence interval)----------------')\n",
    "print('NAIS: [0{1:5.3f},{1:5.3f}]'.format(*find_maximum_prob(emp_result[:,0],95)[:2]))\n",
    "print('AIS:  [{0:5.3f},{1:5.3f}]'.format(*find_maximum_prob(emp_result[:,1],95)[:2]))\n",
    "print('SIS:  [{0:5.3f},{1:5.3f}]'.format(*find_maximum_prob(emp_result[:,2],95)[:2]))\n",
    "print('Total MWP-1A Magnitude:    [{0:5.3f},{1:5.3f}]'.format(*find_maximum_prob(np.sum(emp_result,axis=1),95)[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform senario coral records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------MWP1A Magnitude & Sources with Uniform Distribution -----------\n",
      "----------------95% confidence interval----------------\n",
      "NAIS: [016.114,16.114]\n",
      "AIS:  [0.000,7.563]\n",
      "SIS:  [2.599,6.604]\n",
      "Total MWP-1A Magnitude: [15.068,20.381]\n"
     ]
    }
   ],
   "source": [
    "uni_result = []\n",
    "total_uni_std = np.array([Tahiti_uni_std,Barbados_uni_std,Sunda_uni_std,HYD_uni_std,NOG_uni_std,\n",
    "                        Scot_uni_std])\n",
    "while len(uni_result)<20000:\n",
    "    i = np.random.randint(0,20000,1)[0]\n",
    "    obs = np.array([Tahiti_uni_dis.iloc[i],Barbados_uni_dis.iloc[i],Sunda_uni_dis.iloc[i],HYD_uni_dis.iloc[i],\n",
    "                   NOG_uni_dis.iloc[i],Scot_uni_dis.iloc[i]]) #compile all sample together\n",
    "    opti = list(nnls(np.sqrt(1/np.array(total_uni_std)**2)[:,None] * A,np.sqrt(1/np.array(total_uni_std)**2)*obs)[0]) #non-negative least square\n",
    "    if (opti[0]*0.75+opti[1]*1.09-opti[2]*0.74)<9: # filter out the results producing a sea-level oscillation\n",
    "\n",
    "        uni_result.append(opti)\n",
    "    \n",
    "uni_result= np.array(uni_result)\n",
    "print('----------------MWP1A Magnitude & Sources with Uniform Distribution -----------')\n",
    "print('----------------95% confidence interval----------------')\n",
    "print('NAIS: [0{1:5.3f},{1:5.3f}]'.format(*find_maximum_prob(uni_result[:,0],95)[:2]))\n",
    "print('AIS:  [{0:5.3f},{1:5.3f}]'.format(*find_maximum_prob(uni_result[:,1],95)[:2]))\n",
    "print('SIS:  [{0:5.3f},{1:5.3f}]'.format(*find_maximum_prob(uni_result[:,2],95)[:2]))\n",
    "print('Total MWP-1A Magnitude: [{0:5.3f},{1:5.3f}]'.format(*find_maximum_prob(np.sum(uni_result,axis=1),95)[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaged results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Averaged MWP1A Magnitude & Sources -----------\n",
      "----------------Median Result (95% confidence interval)----------------\n",
      "NAIS: [5.683,15.481]\n",
      "AIS:  [0.000,5.905]\n",
      "SIS:  [3.197,6.327]\n",
      "Total MWP-1A Magnitude: [15.068,20.381]\n"
     ]
    }
   ],
   "source": [
    "print('----------------Averaged MWP1A Magnitude & Sources -----------')\n",
    "print('----------------Median Result (95% confidence interval)----------------')\n",
    "print('NAIS: [{0:5.3f},{1:5.3f}]'.format(*find_maximum_prob((uni_result[:,0]+emp_result[:,0])/2,95)[:2]))\n",
    "print('AIS:  [{0:5.3f},{1:5.3f}]'.format(*find_maximum_prob((uni_result[:,1]+emp_result[:,1])/2,95)[:2]))\n",
    "print('SIS:  [{0:5.3f},{1:5.3f}]'.format(*find_maximum_prob((uni_result[:,2]+emp_result[:,2])/2,95)[:2]))\n",
    "print('Total MWP-1A Magnitude: [{0:5.3f},{1:5.3f}]'.format(*find_maximum_prob(np.sum(uni_result,axis=1),95)[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final notes:\n",
    "\n",
    "- Due to the different ramdom seeds, this code can possibly result in a slightly different results comparing to the results shown in our manuscript\n",
    "- If you have any questions, feedbacks or comments, please feel free to contact [the corresponding author](yc-lin.com): yucheng.lin@durham.ac.uk\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
