{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Basic Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load modules\n",
    "import numpy as np #version 1.18.1\n",
    "import pandas as pd #version 1.0.1\n",
    "from scipy.optimize import nnls #version 1.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load RSL rise magnitude at each site\n",
    "#------------------Empirical Senario------------------\n",
    "Emp_mag = pd.read_excel('RSL magnitude/Lin et al., Sup data.xlsx',sheet_name=1) \n",
    "Tahiti_emp_dis = Emp_mag['Tahiti']\n",
    "Tahiti_emp_std = np.std(Tahiti_emp_dis)\n",
    "Barbados_emp_dis =  Emp_mag['Barbados']\n",
    "Barbados_emp_std = np.std(Barbados_emp_dis)\n",
    "Sunda_emp_dis =  Emp_mag['Sunda Shelf']\n",
    "Sunda_emp_std = np.std(Sunda_emp_dis)\n",
    "HYD_emp_dis =  Emp_mag['Hydrographer\\'s Passage (HYD)']\n",
    "HYD_emp_std = np.std(HYD_emp_dis)\n",
    "NOG_emp_dis =  Emp_mag['Noggin Pass (NOG)']\n",
    "NOG_emp_std = np.std(NOG_emp_dis)\n",
    "Scot_emp_dis =  Emp_mag['Northwest Scotland']\n",
    "Scot_emp_std = np.std(Scot_emp_dis)\n",
    "total_emp_std = np.array([Tahiti_emp_std,Barbados_emp_std,Sunda_emp_std,HYD_emp_std,NOG_emp_std,\n",
    "                        Scot_emp_std]) \n",
    "#------------------Uniform Senario------------------\n",
    "Uni_mag = pd.read_excel('RSL magnitude/Lin et al., Sup data.xlsx',sheet_name=2) #Uniform Senario\n",
    "Tahiti_uni_dis = Uni_mag['Tahiti']\n",
    "Tahiti_uni_std = np.std(Tahiti_uni_dis)\n",
    "Barbados_uni_dis =  Uni_mag['Barbados']\n",
    "Barbados_uni_std = np.std(Barbados_uni_dis)\n",
    "Sunda_uni_dis =  Uni_mag['Sunda Shelf']\n",
    "Sunda_uni_std = np.std(Sunda_uni_dis)\n",
    "HYD_uni_dis =  Uni_mag['Hydrographer\\'s Passage (HYD)']\n",
    "HYD_uni_std = np.std(HYD_uni_dis)\n",
    "NOG_uni_dis =  Uni_mag['Noggin Pass (NOG)']\n",
    "NOG_uni_std = np.std(NOG_uni_dis)\n",
    "Scot_uni_dis =  Uni_mag['Northwest Scotland']\n",
    "Scot_uni_std = np.std(Scot_uni_dis)\n",
    "total_uni_std = np.array([Tahiti_uni_std,Barbados_uni_std,Sunda_uni_std,HYD_uni_std,NOG_uni_std,\n",
    "                        Scot_uni_std])\n",
    "#load sea-level fingerprint matrix\n",
    "#each row corresponds to each sea-level site and each column corresponds to each ice sheet\n",
    "A = np.loadtxt('RSL magnitude/fingerprint.csv',delimiter=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_maximum_prob(values,percent):\n",
    "    '''This function is used to find the defined confidence interval analytically \n",
    "    with highest probablity density  \n",
    "    values:  data samples\n",
    "    percent: probablity range to find'''\n",
    "    \n",
    "    v_max,v_min = np.max(values),np.min(values)\n",
    "    ranges = []\n",
    "    for i in np.linspace(0,100-percent,1000):\n",
    "        _b,_e = np.percentile(values,[i,i+percent])\n",
    "        ranges.append([_b,_e,np.abs(_b-_e),i,i+percent])\n",
    "    ranges = np.array(ranges)\n",
    "    min_index = np.argmin(ranges[:,2])\n",
    "    \n",
    "    return ranges[min_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. MWP-1A Sources Inversion\n",
    "\n",
    "### Empirical senario for coral records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------MWP1A Magnitude & Sources with Empirical Distribution -\n",
      "----------------Mean Result (95% confidence interval)----------------\n",
      "NAIS: 12.291 [0.000,18.631]\n",
      "AIS: 2.540 [0.000,10.692]\n",
      "SIS:   3.459 [0.000,6.572]\n",
      "Total MWP-1A Magnitude:   18.290 [14.270,21.941]\n"
     ]
    }
   ],
   "source": [
    "emp_result = []\n",
    "while len(emp_result)<20000:\n",
    "    i = np.random.randint(0,10000,1)[0]\n",
    "    obs = np.array([Tahiti_emp_dis.iloc[i],Barbados_emp_dis.iloc[i],Sunda_emp_dis.iloc[i],HYD_emp_dis.iloc[i],\n",
    "                   NOG_emp_dis.iloc[i],Scot_emp_dis.iloc[i]]) #compile all sample together\n",
    "    opti = list(nnls(np.sqrt(1/np.array(total_emp_std)**2)[:,None] * A,np.sqrt(1/np.array(total_emp_std)**2)*obs)[0]) #non-negative least square\n",
    "    emp_result.append(opti)\n",
    "    \n",
    "emp_result= np.array(emp_result)\n",
    "print('----------------MWP1A Magnitude & Sources with Empirical Distribution -')\n",
    "print('----------------Mean Result (95% confidence interval)----------------')\n",
    "print('NAIS: {0:5.3f} [{1:5.3f},{2:5.3f}]'.format(np.mean(emp_result[:,0]),*find_maximum_prob(emp_result[:,0],95)[:2]))\n",
    "print('AIS: {0:5.3f} [{1:5.3f},{2:5.3f}]'.format(np.mean(emp_result[:,1]),*find_maximum_prob(emp_result[:,1],95)[:2]))\n",
    "print('SIS:   {0:5.3f} [{1:5.3f},{2:5.3f}]'.format(np.mean(emp_result[:,2]),*find_maximum_prob(emp_result[:,2],95)[:2]))\n",
    "print('Total MWP-1A Magnitude:   {0:5.3f} [{1:5.3f},{2:5.3f}]'.format(np.mean(np.sum(emp_result,axis=1)),*find_maximum_prob(np.sum(emp_result,axis=1),95)[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform senario coral records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------MWP1A Magnitude & Sources with Uniform Distribution -\n",
      "----------------Mean Result (95% confidence interval)----------------\n",
      "NAIS: 12.350 [2.971,19.157]\n",
      "AIS: 2.219 [0.000,9.096]\n",
      "SIS:   3.164 [0.000,5.977]\n",
      "Total MWP-1A Magnitude:   17.733 [14.934,20.490]\n"
     ]
    }
   ],
   "source": [
    "uni_result = []\n",
    "while len(uni_result)<20000:\n",
    "    i = np.random.randint(0,10000,1)[0]\n",
    "    obs = np.array([Tahiti_uni_dis.iloc[i],Barbados_uni_dis.iloc[i],Sunda_uni_dis.iloc[i],HYD_uni_dis.iloc[i],\n",
    "                   NOG_uni_dis.iloc[i],Scot_uni_dis.iloc[i]]) #compile all sample together\n",
    "    opti = list(nnls(np.sqrt(1/np.array(total_uni_std)**2)[:,None] * A,np.sqrt(1/np.array(total_uni_std)**2)*obs)[0]) #non-negative least square\n",
    "    uni_result.append(opti)\n",
    "    \n",
    "uni_result= np.array(uni_result)\n",
    "print('----------------MWP1A Magnitude & Sources with Uniform Distribution -')\n",
    "print('----------------Mean Result (95% confidence interval)----------------')\n",
    "print('NAIS: {0:5.3f} [{1:5.3f},{2:5.3f}]'.format(np.mean(uni_result[:,0]),*find_maximum_prob(uni_result[:,0],95)[:2]))\n",
    "print('AIS: {0:5.3f} [{1:5.3f},{2:5.3f}]'.format(np.mean(uni_result[:,1]),*find_maximum_prob(uni_result[:,1],95)[:2]))\n",
    "print('SIS:   {0:5.3f} [{1:5.3f},{2:5.3f}]'.format(np.mean(uni_result[:,2]),*find_maximum_prob(uni_result[:,2],95)[:2]))\n",
    "print('Total MWP-1A Magnitude:   {0:5.3f} [{1:5.3f},{2:5.3f}]'.format(np.mean(np.sum(uni_result,axis=1)),*find_maximum_prob(np.sum(uni_result,axis=1),95)[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Jackknife Resampling\n",
    "\n",
    "### Empirical senario for coral records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Without Tahiti -------------------------------------\n",
      "----------------MWP1A Magnitude & Sources with Empirical Distribution -----------\n",
      "----------------Mean Result [95% confidence interval] (1 std)-----------------\n",
      "North American Ice Sheet: 11.375 [0.000,19.087]  (6.288)\n",
      "West Antarctic Ice Sheet: 3.124 [0.000,12.029] (4.455)\n",
      "Scandinavian Ice Sheet:   3.450 [0.000,6.586]  (2.028)\n",
      "----------------------------------------------------------------------\n",
      "----------------Without Barbados -------------------------------------\n",
      "----------------MWP1A Magnitude & Sources with Empirical Distribution -----------\n",
      "----------------Mean Result [95% confidence interval] (1 std)-----------------\n",
      "North American Ice Sheet: 7.683 [0.000,18.006]  (7.268)\n",
      "West Antarctic Ice Sheet: 6.825 [0.000,15.983] (6.284)\n",
      "Scandinavian Ice Sheet:   5.115 [0.000,9.973]  (2.972)\n",
      "----------------------------------------------------------------------\n",
      "----------------Without Sunda Shelf -------------------------------------\n",
      "----------------MWP1A Magnitude & Sources with Empirical Distribution -----------\n",
      "----------------Mean Result [95% confidence interval] (1 std)-----------------\n",
      "North American Ice Sheet: 12.513 [0.000,18.668]  (5.059)\n",
      "West Antarctic Ice Sheet: 2.425 [0.000,10.634] (3.653)\n",
      "Scandinavian Ice Sheet:   3.459 [0.000,6.614]  (2.035)\n",
      "----------------------------------------------------------------------\n",
      "----------------Without Hydrographer -------------------------------------\n",
      "----------------MWP1A Magnitude & Sources with Empirical Distribution -----------\n",
      "----------------Mean Result [95% confidence interval] (1 std)-----------------\n",
      "North American Ice Sheet: 11.573 [0.000,18.366]  (5.376)\n",
      "West Antarctic Ice Sheet: 2.985 [0.000,11.191] (3.948)\n",
      "Scandinavian Ice Sheet:   3.364 [0.000,6.497]  (2.027)\n",
      "----------------------------------------------------------------------\n",
      "----------------Without Noggin Pass -------------------------------------\n",
      "----------------MWP1A Magnitude & Sources with Empirical Distribution -----------\n",
      "----------------Mean Result [95% confidence interval] (1 std)-----------------\n",
      "North American Ice Sheet: 12.013 [0.000,18.400]  (5.134)\n",
      "West Antarctic Ice Sheet: 2.671 [0.000,10.861] (3.753)\n",
      "Scandinavian Ice Sheet:   3.443 [0.000,6.562]  (2.031)\n",
      "----------------------------------------------------------------------\n",
      "----------------Without Scotland -------------------------------------\n",
      "----------------MWP1A Magnitude & Sources with Empirical Distribution -----------\n",
      "----------------Mean Result [95% confidence interval] (1 std)-----------------\n",
      "North American Ice Sheet: 13.991 [0.000,21.064]  (6.187)\n",
      "West Antarctic Ice Sheet: 2.928 [0.000,13.227] (4.487)\n",
      "Scandinavian Ice Sheet:   1.388 [0.000,10.511]  (3.641)\n",
      "----------------------------------------------------------------------\n",
      "----------------Overall Jackknife/Original Results --------------------\n",
      "NAIS: 11.525, 12.291  Bias: -0.767 Bias Corrected: 13.058 m\n",
      "AIS: 3.493, 2.540  Bias: 0.953 Bias Corrected: 1.586 m\n",
      "SIS:   3.370, 3.459  Bias: -0.089 Bias Corrected: 3.548 m\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "jack_knife_result =np.zeros([60000,3])\n",
    "site_name = ['Tahiti',\"Barbados\",'Sunda Shelf','Hydrographer','Noggin Pass',\n",
    "            'Scotland']\n",
    "for jack in range(6):\n",
    "    \n",
    "    all_emp_result = [Tahiti_emp_dis,Barbados_emp_dis,Sunda_emp_dis,NOG_emp_dis,\n",
    "                           HYD_emp_dis,Scot_emp_dis]\n",
    "    total_emp_std = [Tahiti_emp_std,Barbados_emp_std,Sunda_emp_std,HYD_emp_std,NOG_emp_std,\n",
    "                         Scot_emp_std]\n",
    "    A_index = ~(np.arange(0,6)==jack)\n",
    "    A_jack = A[A_index]\n",
    "\n",
    "    del all_emp_result[jack] #remove one site's observation\n",
    "    del total_emp_std[jack] #remove one site's standard error \n",
    "    emp_test_result = []\n",
    "    all_emp_result = np.array(all_emp_result)\n",
    "    total_emp_std = np.array(total_emp_std)\n",
    "    while len(emp_test_result)<10000:\n",
    "        \n",
    "        i = np.random.randint(0,10000,1)[0]\n",
    "        obs = np.array([Tahiti_emp_dis.iloc[i],Barbados_emp_dis.iloc[i],Sunda_emp_dis.iloc[i],HYD_emp_dis.iloc[i],\n",
    "                       NOG_emp_dis.iloc[i],Scot_emp_dis.iloc[i]])\n",
    "        obs = obs[A_index] \n",
    "        opti = list(nnls(np.sqrt(1/np.array(total_emp_std)**2)[:,None] * A_jack,np.sqrt(1/np.array(total_emp_std)**2)*obs)[0])\n",
    "        emp_test_result.append(opti)\n",
    "       \n",
    "    \n",
    "    emp_test_result= np.array(emp_test_result)\n",
    "    jack_knife_result[jack*10000:(jack+1)*10000,:]=emp_test_result\n",
    "    print('----------------Without {:} -------------------------------------'.format(site_name[jack]))\n",
    "    print('----------------MWP1A Magnitude & Sources with Empirical Distribution -----------')\n",
    "    print('----------------Mean Result [95% confidence interval] (1 std)-----------------')\n",
    "    print('North American Ice Sheet: {0:5.3f} [{1:5.3f},{2:5.3f}]  ({3:5.3f})'.format(np.mean(emp_test_result[:,0]),find_maximum_prob(emp_test_result[:,0],95)[0],find_maximum_prob(emp_test_result[:,0],95)[1],\n",
    "                                                                                   np.std(emp_test_result[:,0])))\n",
    "    print('West Antarctic Ice Sheet: {0:5.3f} [{1:5.3f},{2:5.3f}] ({3:5.3f})'.format(np.mean(emp_test_result[:,1]),find_maximum_prob(emp_test_result[:,1],95)[0],find_maximum_prob(emp_test_result[:,1],95)[1],\n",
    "                                                                                  np.std(emp_test_result[:,1])))\n",
    "    print('Scandinavian Ice Sheet:   {0:5.3f} [{1:5.3f},{2:5.3f}]  ({3:5.3f})'.format(np.mean(emp_test_result[:,2]),find_maximum_prob(emp_test_result[:,2],95)[0],find_maximum_prob(emp_test_result[:,2],95)[1],\n",
    "                                                                                  np.std(emp_test_result[:,2])))\n",
    "    print('----------------------------------------------------------------------')\n",
    "\n",
    "print('----------------Overall Jackknife/Original Results --------------------')\n",
    "print('NAIS: {0:5.3f}, {1:5.3f}  Bias: {2:5.3f} Bias Corrected: {3:5.3f} m'.format(np.mean(jack_knife_result[:,0]),np.mean(emp_result[:,0]),\n",
    "                                                                           np.mean(jack_knife_result[:,0])-np.mean(emp_result[:,0]),\n",
    "                                                                            np.mean(emp_result[:,0])-(np.mean(jack_knife_result[:,0])-np.mean(emp_result[:,0]))))\n",
    "print('AIS: {0:5.3f}, {1:5.3f}  Bias: {2:5.3f} Bias Corrected: {3:5.3f} m'.format(np.mean(jack_knife_result[:,1]),np.mean(emp_result[:,1]),\n",
    "                                                                           np.mean(jack_knife_result[:,1])-np.mean(emp_result[:,1]),\n",
    "                                                                           np.mean(emp_result[:,1])-(np.mean(jack_knife_result[:,1])-np.mean(emp_result[:,1]))))\n",
    "print('SIS:   {0:5.3f}, {1:5.3f}  Bias: {2:5.3f} Bias Corrected: {3:5.3f} m'.format(np.mean(jack_knife_result[:,2]),np.mean(emp_result[:,2]),\n",
    "                                                                          np.mean(jack_knife_result[:,2])-np.mean(emp_result[:,2]),\n",
    "                                                                        np.mean(emp_result[:,2])-( np.mean(jack_knife_result[:,2])-np.mean(emp_result[:,2]))))\n",
    "print('----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform senario coral records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Without Tahiti -------------------------------------\n",
      "----------------MWP1A Magnitude & Sources with Uniform Distribution -----------\n",
      "----------------Mean Result [95% confidence interval] (1 std)-----------------\n",
      "North American Ice Sheet: 10.463 [0.000,18.335]  (4.252)\n",
      "West Antarctic Ice Sheet: 3.397 [0.000,11.578] (4.300)\n",
      "Scandinavian Ice Sheet:   3.228 [0.000,6.000]  (1.896)\n",
      "----------------------------------------------------------------------\n",
      "----------------Without Barbados -------------------------------------\n",
      "----------------MWP1A Magnitude & Sources with Uniform Distribution -----------\n",
      "----------------Mean Result [95% confidence interval] (1 std)-----------------\n",
      "North American Ice Sheet: 8.855 [0.000,17.120]  (4.252)\n",
      "West Antarctic Ice Sheet: 5.367 [0.000,15.150] (5.884)\n",
      "Scandinavian Ice Sheet:   4.413 [0.000,8.764]  (2.606)\n",
      "----------------------------------------------------------------------\n",
      "----------------Without Sunda Shelf -------------------------------------\n",
      "----------------MWP1A Magnitude & Sources with Uniform Distribution -----------\n",
      "----------------Mean Result [95% confidence interval] (1 std)-----------------\n",
      "North American Ice Sheet: 12.492 [3.335,19.578]  (4.252)\n",
      "West Antarctic Ice Sheet: 2.149 [0.000,8.886] (3.058)\n",
      "Scandinavian Ice Sheet:   3.142 [0.000,5.963]  (1.905)\n",
      "----------------------------------------------------------------------\n",
      "----------------Without Hydrographer -------------------------------------\n",
      "----------------MWP1A Magnitude & Sources with Uniform Distribution -----------\n",
      "----------------Mean Result [95% confidence interval] (1 std)-----------------\n",
      "North American Ice Sheet: 12.246 [2.626,18.972]  (4.252)\n",
      "West Antarctic Ice Sheet: 2.252 [0.000,8.911] (3.072)\n",
      "Scandinavian Ice Sheet:   3.172 [0.000,6.025]  (1.892)\n",
      "----------------------------------------------------------------------\n",
      "----------------Without Noggin Pass -------------------------------------\n",
      "----------------MWP1A Magnitude & Sources with Uniform Distribution -----------\n",
      "----------------Mean Result [95% confidence interval] (1 std)-----------------\n",
      "North American Ice Sheet: 12.181 [2.446,19.496]  (4.252)\n",
      "West Antarctic Ice Sheet: 2.322 [0.000,9.218] (3.155)\n",
      "Scandinavian Ice Sheet:   3.116 [0.000,5.910]  (1.886)\n",
      "----------------------------------------------------------------------\n",
      "----------------Without Scotland -------------------------------------\n",
      "----------------MWP1A Magnitude & Sources with Uniform Distribution -----------\n",
      "----------------Mean Result [95% confidence interval] (1 std)-----------------\n",
      "North American Ice Sheet: 13.577 [2.845,20.944]  (4.252)\n",
      "West Antarctic Ice Sheet: 2.264 [0.000,9.971] (3.580)\n",
      "Scandinavian Ice Sheet:   1.918 [0.000,11.763]  (3.922)\n",
      "----------------------------------------------------------------------\n",
      "----------------Overall Jackknife/Original Results --------------------\n",
      "NAIS: 11.636, 12.350  Bias: -0.714 Bias Corrected: 13.064 m\n",
      "AIS: 2.958, 2.219  Bias: 0.740 Bias Corrected: 1.479 m\n",
      "SIS:   3.165, 3.164  Bias: 0.000 Bias Corrected: 3.164 m\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "jack_knife_result =np.zeros([60000,3])\n",
    "site_name = ['Tahiti',\"Barbados\",'Sunda Shelf','Hydrographer','Noggin Pass',\n",
    "            'Scotland']\n",
    "for jack in range(6):\n",
    "    \n",
    "    all_uni_result = [Tahiti_uni_dis,Barbados_uni_dis,Sunda_uni_dis,NOG_uni_dis,\n",
    "                           HYD_uni_dis,Scot_uni_dis]\n",
    "    total_uni_std = [Tahiti_uni_std,Barbados_uni_std,Sunda_uni_std,HYD_uni_std,NOG_uni_std,\n",
    "                         Scot_uni_std]\n",
    "    A_index = ~(np.arange(0,6)==jack)\n",
    "    A_jack = A[A_index]\n",
    "\n",
    "    del all_uni_result[jack] #remove one site's observation\n",
    "    del total_uni_std[jack] #remove one site's standard error \n",
    "    uni_test_result = []\n",
    "    all_uni_result = np.array(all_uni_result)\n",
    "    total_uni_std = np.array(total_uni_std)\n",
    "    while len(uni_test_result)<10000:\n",
    "        \n",
    "        i = np.random.randint(0,10000,1)[0]\n",
    "        obs = np.array([Tahiti_uni_dis.iloc[i],Barbados_uni_dis.iloc[i],Sunda_uni_dis.iloc[i],HYD_uni_dis.iloc[i],\n",
    "                       NOG_uni_dis.iloc[i],Scot_uni_dis.iloc[i]])\n",
    "        obs = obs[A_index] \n",
    "        opti = list(nnls(np.sqrt(1/np.array(total_uni_std)**2)[:,None] * A_jack,np.sqrt(1/np.array(total_uni_std)**2)*obs)[0])\n",
    "        uni_test_result.append(opti)\n",
    "       \n",
    "    \n",
    "    uni_test_result= np.array(uni_test_result)\n",
    "    jack_knife_result[jack*10000:(jack+1)*10000,:]=uni_test_result\n",
    "    print('----------------Without {:} -------------------------------------'.format(site_name[jack]))\n",
    "    print('----------------MWP1A Magnitude & Sources with Uniform Distribution -----------')\n",
    "    print('----------------Mean Result [95% confidence interval] (1 std)-----------------')\n",
    "    print('North American Ice Sheet: {0:5.3f} [{1:5.3f},{2:5.3f}]  ({3:5.3f})'.format(np.mean(uni_test_result[:,0]),find_maximum_prob(uni_test_result[:,0],95)[0],find_maximum_prob(uni_test_result[:,0],95)[1],\n",
    "                                                                                   np.std(uni_result[:,0])))\n",
    "    print('West Antarctic Ice Sheet: {0:5.3f} [{1:5.3f},{2:5.3f}] ({3:5.3f})'.format(np.mean(uni_test_result[:,1]),find_maximum_prob(uni_test_result[:,1],95)[0],find_maximum_prob(uni_test_result[:,1],95)[1],\n",
    "                                                                                  np.std(uni_test_result[:,1])))\n",
    "    print('Scandinavian Ice Sheet:   {0:5.3f} [{1:5.3f},{2:5.3f}]  ({3:5.3f})'.format(np.mean(uni_test_result[:,2]),find_maximum_prob(uni_test_result[:,2],95)[0],find_maximum_prob(uni_test_result[:,2],95)[1],\n",
    "                                                                                  np.std(uni_test_result[:,2])))\n",
    "    print('----------------------------------------------------------------------')\n",
    "\n",
    "print('----------------Overall Jackknife/Original Results --------------------')\n",
    "print('NAIS: {0:5.3f}, {1:5.3f}  Bias: {2:5.3f} Bias Corrected: {3:5.3f} m'.format(np.mean(jack_knife_result[:,0]),np.mean(uni_result[:,0]),\n",
    "                                                                           np.mean(jack_knife_result[:,0])-np.mean(uni_result[:,0]),\n",
    "                                                                            np.mean(uni_result[:,0])-(np.mean(jack_knife_result[:,0])-np.mean(uni_result[:,0]))))\n",
    "print('AIS: {0:5.3f}, {1:5.3f}  Bias: {2:5.3f} Bias Corrected: {3:5.3f} m'.format(np.mean(jack_knife_result[:,1]),np.mean(uni_result[:,1]),\n",
    "                                                                           np.mean(jack_knife_result[:,1])-np.mean(uni_result[:,1]),\n",
    "                                                                           np.mean(uni_result[:,1])-(np.mean(jack_knife_result[:,1])-np.mean(uni_result[:,1]))))\n",
    "print('SIS:   {0:5.3f}, {1:5.3f}  Bias: {2:5.3f} Bias Corrected: {3:5.3f} m'.format(np.mean(jack_knife_result[:,2]),np.mean(uni_result[:,2]),\n",
    "                                                                          np.mean(jack_knife_result[:,2])-np.mean(uni_result[:,2]),\n",
    "                                                                        np.mean(uni_result[:,2])-( np.mean(jack_knife_result[:,2])-np.mean(uni_result[:,2]))))\n",
    "print('----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. MWP-1A Sources Inversion with sea-level oscillation limit\n",
    "\n",
    "### Empirical senario for coral records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------MWP1A Magnitude & Sources with Empirical Distribution -----------\n",
      "----------------Mean Result (95% confidence interval)----------------\n",
      "NAIS: [015.680,15.680]\n",
      "AIS:  [0.000,9.661]\n",
      "SIS:  [2.708,7.363]\n",
      "Total MWP-1A Magnitude:    [14.412,21.730]\n"
     ]
    }
   ],
   "source": [
    "emp_result = []\n",
    "total_emp_std = np.array([Tahiti_emp_std,Barbados_emp_std,Sunda_emp_std,HYD_emp_std,NOG_emp_std,\n",
    "                        Scot_emp_std]) \n",
    "while len(emp_result)<20000:\n",
    "    i = np.random.randint(0,10000,1)[0]\n",
    "    obs = np.array([Tahiti_emp_dis.iloc[i],Barbados_emp_dis.iloc[i],Sunda_emp_dis.iloc[i],HYD_emp_dis.iloc[i],\n",
    "                   NOG_emp_dis.iloc[i],Scot_emp_dis.iloc[i]]) #compile all sample together\n",
    "    opti = list(nnls(np.sqrt(1/np.array(total_emp_std)**2)[:,None] * A,np.sqrt(1/np.array(total_emp_std)**2)*obs)[0]) #non-negative least square\n",
    "    if (opti[0]*0.75+opti[1]*1.09-opti[2]*0.74)<9: # filter out the results producing a sea-level oscillation\n",
    "        emp_result.append(opti)\n",
    "    \n",
    "emp_result= np.array(emp_result)\n",
    "print('----------------MWP1A Magnitude & Sources with Empirical Distribution -----------')\n",
    "print('----------------Mean Result (95% confidence interval)----------------')\n",
    "print('NAIS: [0{1:5.3f},{1:5.3f}]'.format(*find_maximum_prob(emp_result[:,0],95)[:2]))\n",
    "print('AIS:  [{0:5.3f},{1:5.3f}]'.format(*find_maximum_prob(emp_result[:,1],95)[:2]))\n",
    "print('SIS:  [{0:5.3f},{1:5.3f}]'.format(*find_maximum_prob(emp_result[:,2],95)[:2]))\n",
    "print('Total MWP-1A Magnitude:    [{0:5.3f},{1:5.3f}]'.format(*find_maximum_prob(np.sum(emp_result,axis=1),95)[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform senario coral records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------MWP1A Magnitude & Sources with Uniform Distribution -----------\n",
      "----------------95% confidence interval----------------\n",
      "NAIS: [016.166,16.166]\n",
      "AIS:  [0.000,7.624]\n",
      "SIS:  [2.579,6.583]\n",
      "Total MWP-1A Magnitude: [15.078,20.362]\n"
     ]
    }
   ],
   "source": [
    "uni_result = []\n",
    "total_uni_std = np.array([Tahiti_uni_std,Barbados_uni_std,Sunda_uni_std,HYD_uni_std,NOG_uni_std,\n",
    "                        Scot_uni_std])\n",
    "while len(uni_result)<20000:\n",
    "    i = np.random.randint(0,10000,1)[0]\n",
    "    obs = np.array([Tahiti_uni_dis.iloc[i],Barbados_uni_dis.iloc[i],Sunda_uni_dis.iloc[i],HYD_uni_dis.iloc[i],\n",
    "                   NOG_uni_dis.iloc[i],Scot_uni_dis.iloc[i]]) #compile all sample together\n",
    "    opti = list(nnls(np.sqrt(1/np.array(total_uni_std)**2)[:,None] * A,np.sqrt(1/np.array(total_uni_std)**2)*obs)[0]) #non-negative least square\n",
    "    if (opti[0]*0.75+opti[1]*1.09-opti[2]*0.74)<9: # filter out the results producing a sea-level oscillation\n",
    "\n",
    "        uni_result.append(opti)\n",
    "    \n",
    "uni_result= np.array(uni_result)\n",
    "print('----------------MWP1A Magnitude & Sources with Uniform Distribution -----------')\n",
    "print('----------------95% confidence interval----------------')\n",
    "print('NAIS: [0{1:5.3f},{1:5.3f}]'.format(*find_maximum_prob(uni_result[:,0],95)[:2]))\n",
    "print('AIS:  [{0:5.3f},{1:5.3f}]'.format(*find_maximum_prob(uni_result[:,1],95)[:2]))\n",
    "print('SIS:  [{0:5.3f},{1:5.3f}]'.format(*find_maximum_prob(uni_result[:,2],95)[:2]))\n",
    "print('Total MWP-1A Magnitude: [{0:5.3f},{1:5.3f}]'.format(*find_maximum_prob(np.sum(uni_result,axis=1),95)[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaged results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Averaged MWP1A Magnitude & Sources -----------\n",
      "----------------Median Result (95% confidence interval)----------------\n",
      "NAIS: [5.523,15.416]\n",
      "AIS:  [0.000,5.934]\n",
      "SIS:  [3.209,6.333]\n",
      "Total MWP-1A Magnitude: [15.078,20.362]\n"
     ]
    }
   ],
   "source": [
    "print('----------------Averaged MWP1A Magnitude & Sources -----------')\n",
    "print('----------------Median Result (95% confidence interval)----------------')\n",
    "print('NAIS: [{0:5.3f},{1:5.3f}]'.format(*find_maximum_prob((uni_result[:,0]+emp_result[:,0])/2,95)[:2]))\n",
    "print('AIS:  [{0:5.3f},{1:5.3f}]'.format(*find_maximum_prob((uni_result[:,1]+emp_result[:,1])/2,95)[:2]))\n",
    "print('SIS:  [{0:5.3f},{1:5.3f}]'.format(*find_maximum_prob((uni_result[:,2]+emp_result[:,2])/2,95)[:2]))\n",
    "print('Total MWP-1A Magnitude: [{0:5.3f},{1:5.3f}]'.format(*find_maximum_prob(np.sum(uni_result,axis=1),95)[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final notes:\n",
    "\n",
    "- Due to the different ramdom seeds, this code can possibly result in a slightly different results comparing to the results shown in our manuscript\n",
    "- If you have any questions, please feel free to contact [the corresponding author](yc-lin.com): yucheng.lin@durham.ac.uk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
